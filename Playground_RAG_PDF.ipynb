{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import openai\n",
    "import io\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain_community.document_loaders import WebBaseLoader, DirectoryLoader, TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Load, chunk and index the contents of the blog.\n",
    "loader = PyPDFLoader(\"data/writegreatcode_vol2.pdf\")\n",
    "docs = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, try to answer the question.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "#create question and answer chain and combine chains\n",
    "\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    ai_msg = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "    print(ai_msg[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This PDF appears to be about a book titled \"Write Great Code: Thinking Low-Level, Writing High-Level\" by Randall Hyde. The book focuses on the aspect of writing efficient and high-performance code. It is not about optimization, but rather about understanding how to write code that performs well. The book is part of the Write Great Code series.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "ask_question(\"what is this pdf about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Premature optimization can lead to problems in software design. It's not usually worth spending a lot of time micro-optimizing code before it's clear where the performance bottlenecks are.\n",
      "\n",
      "2. However, performance issues should always be considered from the beginning when designing software at a system level.\n",
      "\n",
      "3. Great code has several attributes: it uses the CPU, memory, and system resources efficiently; it is easy to read and maintain; and it follows a consistent set of style guidelines.\n",
      "\n",
      "4. No matter how efficient your code is, if it is not readable and maintainable by others, then itâ€™s not great code. \n",
      "\n",
      "5. Writing great code involves a personal level of craftsmanship, art, and pride in workmanship. \n",
      "\n",
      "6. Coding styles, commenting, code layout, and other coding tasks contribute to making code readable and easy to maintain.\n"
     ]
    }
   ],
   "source": [
    "ask_question(\"give me some takeaways\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chapters in this PDF are:\n",
      "\n",
      "1. Chapter 5: Compiler Operation and Code Generation\n",
      "2. Chapter 6: Tools for Analyzing Compiler Output\n",
      "3. Chapter 7: Constants and High-Level Languages\n",
      "4. Chapter 8: Variables in a High-Level Language\n",
      "5. Chapter 9: Array Data Types\n",
      "6. Chapter 10: String Data Types\n",
      "7. Chapter 11: Pointer Data Types\n",
      "8. Chapter 12: Record, Union, and Class Data Types\n",
      "9. Chapter 13: Arithmetic and Logical Expressions\n",
      "10. Chapter 14: Control Structures and Programmatic Decisions\n",
      "11. Chapter 15: Iterative Control Structures\n",
      "12. Chapter 16: Functions and Procedures\n",
      "\n",
      "There are also sections on Engineering Software, an Appendix comparing the 80x86 and PowerPC CPU Families, and Online Appendices.\n"
     ]
    }
   ],
   "source": [
    "ask_question(\"list me the chapters in this pdf.\")\n",
    "#some chapters are missing from the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text doesn't provide specific information about the content of chapters 1-4. However, it mentions that chapters 3 and 4 provide a quick primer for 80x86 and PowerPC assembly language. The content of chapters 1 and 2 is not specified in the provided text.\n"
     ]
    }
   ],
   "source": [
    "ask_question(\"what about chapters 1-4?\")\n",
    "#unfortunately, the model does not know the answer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
